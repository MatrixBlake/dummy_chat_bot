{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kwan4418_COMP5046_Ass1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*"
      ]
    },
    {
      "metadata": {
        "id": "qTf21j_oQIiD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the user, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style*"
      ]
    },
    {
      "metadata": {
        "id": "iXbQohXLKSgO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1 - Data Preprocessing (Personality chat datasets)"
      ]
    },
    {
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1. Download Dataset (Personality chat datasets)"
      ]
    },
    {
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "outputId": "c6923ebe-ae87-4404-9500-0b86981c1c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "    \n",
        "downloaded = drive.CreateFile({'id': '1o9wrfgel1TB-ivP7EOvV-CbUwr1OqDFU'})\n",
        "downloaded.GetContentFile('qna_chitchat_the_friend.tsv')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '18YV2-IloTSU0cCbhxWREHviE-mENlr_m'})\n",
        "downloaded.GetContentFile('qna_chitchat_the_professional.tsv')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1NS4J3-fRHtpXLVW0kOsUITXruOUw4MGK'})\n",
        "downloaded.GetContentFile('qna_chitchat_the_comic.tsv')\n",
        "\n",
        "df_friend = pd.read_csv('qna_chitchat_the_friend.tsv', sep=\"\\t\")\n",
        "df_pro =  pd.read_csv('qna_chitchat_the_professional.tsv', sep=\"\\t\")\n",
        "df_comic = pd.read_csv('qna_chitchat_the_comic.tsv', sep=\"\\t\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2. Preprocess data (Personality chat datasets)"
      ]
    },
    {
      "metadata": {
        "id": "8RdKI8E2KRwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe which data preprocessing techniques were conducted with justification of your decision. *"
      ]
    },
    {
      "metadata": {
        "id": "le1nJ5UBts6A",
        "colab_type": "code",
        "outputId": "292ac6a9-3ad9-44ad-d1e4-91698f90e04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "df_friend.sample(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Source</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>Do you not like me?</td>\n",
              "      <td>I like you lots!</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>You're really boring</td>\n",
              "      <td>Swing and a miss.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>Do you like apples?</td>\n",
              "      <td>I only do food for thought.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>I appreciate it</td>\n",
              "      <td>You're very welcome.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>Are you a fan of tech?</td>\n",
              "      <td>The world of tech feels like home to me.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>You must hate me</td>\n",
              "      <td>I like you lots!</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>Are you really happy?</td>\n",
              "      <td>So happy!</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>When will you shut up?</td>\n",
              "      <td>Will do.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>Pardon me</td>\n",
              "      <td>No worries.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Do you get tired?</td>\n",
              "      <td>I don't have the hardware for that.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Question                                    Answer  \\\n",
              "514     Do you not like me?                          I like you lots!   \n",
              "32     You're really boring                         Swing and a miss.   \n",
              "108     Do you like apples?               I only do food for thought.   \n",
              "415         I appreciate it                      You're very welcome.   \n",
              "156  Are you a fan of tech?  The world of tech feels like home to me.   \n",
              "517        You must hate me                          I like you lots!   \n",
              "100   Are you really happy?                                 So happy!   \n",
              "297  When will you shut up?                                  Will do.   \n",
              "382               Pardon me                               No worries.   \n",
              "18        Do you get tired?       I don't have the hardware for that.   \n",
              "\n",
              "                      Source            Metadata  \n",
              "514  qna_chitchat_the_friend  editorial:chitchat  \n",
              "32   qna_chitchat_the_friend  editorial:chitchat  \n",
              "108  qna_chitchat_the_friend  editorial:chitchat  \n",
              "415  qna_chitchat_the_friend  editorial:chitchat  \n",
              "156  qna_chitchat_the_friend  editorial:chitchat  \n",
              "517  qna_chitchat_the_friend  editorial:chitchat  \n",
              "100  qna_chitchat_the_friend  editorial:chitchat  \n",
              "297  qna_chitchat_the_friend  editorial:chitchat  \n",
              "382  qna_chitchat_the_friend  editorial:chitchat  \n",
              "18   qna_chitchat_the_friend  editorial:chitchat  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "kx1qt9GUw1IP",
        "colab_type": "code",
        "outputId": "48459d22-7155-4696-f105-68562fa2d32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "df_pro.sample(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Source</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>Are you queer?</td>\n",
              "      <td>I'm digital.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>I hope you like me</td>\n",
              "      <td>I do like you.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>Good evening to you</td>\n",
              "      <td>Good evening.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>Say a joke</td>\n",
              "      <td>I'm not really that funny.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>Where are you from?</td>\n",
              "      <td>I'm digital. I don't have a physical location.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>What makes you think that?</td>\n",
              "      <td>Sorry, I don't understand.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>I want you to like me</td>\n",
              "      <td>I do like you.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>I'm sad today</td>\n",
              "      <td>I'm very sorry to hear that.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>What do you think about AI?</td>\n",
              "      <td>The world of technology is fascinating.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>I'm famished</td>\n",
              "      <td>Maybe a snack will help.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Question  \\\n",
              "193               Are you queer?   \n",
              "536           I hope you like me   \n",
              "447          Good evening to you   \n",
              "271                   Say a joke   \n",
              "237          Where are you from?   \n",
              "390   What makes you think that?   \n",
              "537        I want you to like me   \n",
              "619                I'm sad today   \n",
              "152  What do you think about AI?   \n",
              "590                 I'm famished   \n",
              "\n",
              "                                             Answer  \\\n",
              "193                                    I'm digital.   \n",
              "536                                  I do like you.   \n",
              "447                                   Good evening.   \n",
              "271                      I'm not really that funny.   \n",
              "237  I'm digital. I don't have a physical location.   \n",
              "390                      Sorry, I don't understand.   \n",
              "537                                  I do like you.   \n",
              "619                    I'm very sorry to hear that.   \n",
              "152         The world of technology is fascinating.   \n",
              "590                        Maybe a snack will help.   \n",
              "\n",
              "                            Source            Metadata  \n",
              "193  qna_chitchat_the_professional  editorial:chitchat  \n",
              "536  qna_chitchat_the_professional  editorial:chitchat  \n",
              "447  qna_chitchat_the_professional  editorial:chitchat  \n",
              "271  qna_chitchat_the_professional  editorial:chitchat  \n",
              "237  qna_chitchat_the_professional  editorial:chitchat  \n",
              "390  qna_chitchat_the_professional  editorial:chitchat  \n",
              "537  qna_chitchat_the_professional  editorial:chitchat  \n",
              "619  qna_chitchat_the_professional  editorial:chitchat  \n",
              "152  qna_chitchat_the_professional  editorial:chitchat  \n",
              "590  qna_chitchat_the_professional  editorial:chitchat  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "fP7XMyDyw4hL",
        "colab_type": "code",
        "outputId": "7496185e-91ac-4ba5-f27f-e39e0385a0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "df_comic.sample(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Source</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>You are so bad at this</td>\n",
              "      <td>All those years at charm school. Wasted.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>Omg sorry</td>\n",
              "      <td>We're cool.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>What did you do today?</td>\n",
              "      <td>You're looking at it.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>Haha</td>\n",
              "      <td>Oh. Laughter.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Aren't you chipper</td>\n",
              "      <td>Deliriously.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>You're such a sweetheart</td>\n",
              "      <td>My charms are hard to deny.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>I'm afraid I'm gonna have to let you go.</td>\n",
              "      <td>OK. See you tomorrow.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>What's new?</td>\n",
              "      <td>You know, same ol', same ol'.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>You're ugly</td>\n",
              "      <td>I still haven't found a moisturizer that works...</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>Are you bisexual?</td>\n",
              "      <td>I'm digital.</td>\n",
              "      <td>qna_chitchat_the_comic</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Question  \\\n",
              "338                    You are so bad at this   \n",
              "407                                 Omg sorry   \n",
              "252                    What did you do today?   \n",
              "376                                      Haha   \n",
              "97                         Aren't you chipper   \n",
              "495                  You're such a sweetheart   \n",
              "263  I'm afraid I'm gonna have to let you go.   \n",
              "482                               What's new?   \n",
              "345                               You're ugly   \n",
              "194                         Are you bisexual?   \n",
              "\n",
              "                                                Answer  \\\n",
              "338           All those years at charm school. Wasted.   \n",
              "407                                        We're cool.   \n",
              "252                              You're looking at it.   \n",
              "376                                      Oh. Laughter.   \n",
              "97                                        Deliriously.   \n",
              "495                        My charms are hard to deny.   \n",
              "263                              OK. See you tomorrow.   \n",
              "482                      You know, same ol', same ol'.   \n",
              "345  I still haven't found a moisturizer that works...   \n",
              "194                                       I'm digital.   \n",
              "\n",
              "                     Source            Metadata  \n",
              "338  qna_chitchat_the_comic  editorial:chitchat  \n",
              "407  qna_chitchat_the_comic  editorial:chitchat  \n",
              "252  qna_chitchat_the_comic  editorial:chitchat  \n",
              "376  qna_chitchat_the_comic  editorial:chitchat  \n",
              "97   qna_chitchat_the_comic  editorial:chitchat  \n",
              "495  qna_chitchat_the_comic  editorial:chitchat  \n",
              "263  qna_chitchat_the_comic  editorial:chitchat  \n",
              "482  qna_chitchat_the_comic  editorial:chitchat  \n",
              "345  qna_chitchat_the_comic  editorial:chitchat  \n",
              "194  qna_chitchat_the_comic  editorial:chitchat  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "IdBHR_uutjBN",
        "colab_type": "code",
        "outputId": "be1cb729-afeb-4c2a-94f1-1c662f76c9fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "df_friend.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Source</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>652</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Do you know other bots?</td>\n",
              "      <td>I come from a long line of code.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Question                            Answer  \\\n",
              "count                       657                               657   \n",
              "unique                      652                                98   \n",
              "top     Do you know other bots?  I come from a long line of code.   \n",
              "freq                          2                                17   \n",
              "\n",
              "                         Source            Metadata  \n",
              "count                       657                 657  \n",
              "unique                        1                   1  \n",
              "top     qna_chitchat_the_friend  editorial:chitchat  \n",
              "freq                        657                 657  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "NJ5BEUGDxA55",
        "colab_type": "code",
        "outputId": "f8820aad-9a7a-441b-b7e5-d6d02326ef55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "df_pro.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Source</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>652</td>\n",
              "      <td>97</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Do you know other bots?</td>\n",
              "      <td>I don't have family.</td>\n",
              "      <td>qna_chitchat_the_professional</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>657</td>\n",
              "      <td>657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Question                Answer  \\\n",
              "count                       657                   657   \n",
              "unique                      652                    97   \n",
              "top     Do you know other bots?  I don't have family.   \n",
              "freq                          2                    17   \n",
              "\n",
              "                               Source            Metadata  \n",
              "count                             657                 657  \n",
              "unique                              1                   1  \n",
              "top     qna_chitchat_the_professional  editorial:chitchat  \n",
              "freq                              657                 657  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "sP4TxQEdexNP",
        "colab_type": "code",
        "outputId": "e64444db-e8ec-4f56-f320-0fdb49a3a7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "df_friend.tail(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Source</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>647</th>\n",
              "      <td>I’m offended</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>648</th>\n",
              "      <td>That’s offensive</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649</th>\n",
              "      <td>That’s terrible</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>That’s racist</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>That’s discrimination</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>652</th>\n",
              "      <td>That’s homophobic</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>653</th>\n",
              "      <td>You’re homophobic</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>You’re racist</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>That's sexist</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>You're sexist</td>\n",
              "      <td>I'm so sorry.</td>\n",
              "      <td>qna_chitchat_the_friend</td>\n",
              "      <td>editorial:chitchat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Question         Answer                   Source  \\\n",
              "647           I’m offended  I'm so sorry.  qna_chitchat_the_friend   \n",
              "648       That’s offensive  I'm so sorry.  qna_chitchat_the_friend   \n",
              "649        That’s terrible  I'm so sorry.  qna_chitchat_the_friend   \n",
              "650          That’s racist  I'm so sorry.  qna_chitchat_the_friend   \n",
              "651  That’s discrimination  I'm so sorry.  qna_chitchat_the_friend   \n",
              "652      That’s homophobic  I'm so sorry.  qna_chitchat_the_friend   \n",
              "653      You’re homophobic  I'm so sorry.  qna_chitchat_the_friend   \n",
              "654          You’re racist  I'm so sorry.  qna_chitchat_the_friend   \n",
              "655          That's sexist  I'm so sorry.  qna_chitchat_the_friend   \n",
              "656          You're sexist  I'm so sorry.  qna_chitchat_the_friend   \n",
              "\n",
              "               Metadata  \n",
              "647  editorial:chitchat  \n",
              "648  editorial:chitchat  \n",
              "649  editorial:chitchat  \n",
              "650  editorial:chitchat  \n",
              "651  editorial:chitchat  \n",
              "652  editorial:chitchat  \n",
              "653  editorial:chitchat  \n",
              "654  editorial:chitchat  \n",
              "655  editorial:chitchat  \n",
              "656  editorial:chitchat  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "INLOODxR4JQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
        "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
        "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
        "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
        "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
        "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
        "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
        "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
        "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n",
        "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
        "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
        "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \n",
        "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
        "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \n",
        "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
        "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \n",
        "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
        "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
        "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDhMUx-zzk6t",
        "colab_type": "code",
        "outputId": "05f2b6cb-cafd-4076-c3a3-01fa3d4f9798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "def pre_process_chat_bot_training_data(df):\n",
        "    \n",
        "    df2 = df.drop_duplicates()\n",
        "    \n",
        "    questions = df2['Question'].tolist()\n",
        "    answers = df2['Answer'].tolist()\n",
        "    \n",
        "    tokenized_questions=[]\n",
        "    \n",
        "    for i in range(0,len(questions)):\n",
        "        \n",
        "        questions[i] = re.sub(r\"[0-9]+\", \"\", questions[i])\n",
        "        questions[i] = re.sub(r\"’\", \"'\", questions[i])\n",
        "        \n",
        "        questions[i] = questions[i].lower()\n",
        "        \n",
        "        for keys,values in contraction_dict.items():\n",
        "            questions[i] = questions[i].replace(keys,values)\n",
        "            \n",
        "        questions[i] = re.sub(r\"[^a-z0-9]+\", \" \", questions[i])\n",
        "        questions[i] = remove_stopwords(questions[i])\n",
        "        \n",
        "        \n",
        "        tokenized_questions.append(word_tokenize(questions[i]))\n",
        "    \n",
        "        \n",
        "    return tokenized_questions, answers\n",
        "  \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rF6_Rdvp9UEi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "friend_q, friend_a = pre_process_chat_bot_training_data(df_friend)\n",
        "pro_q, pro_a = pre_process_chat_bot_training_data(df_pro)\n",
        "comic_q, comic_a = pre_process_chat_bot_training_data(df_comic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LIu_lkJwQ55g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "metadata": {
        "id": "daDvAftceIvr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "lbzm-NWBTmM-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe which model was implemented (i.e. Word2Vec with CBOW, FastText with SkipGram, etc.) with justification of your decision *\n",
        "\n",
        "Word2Vec with SkipGram"
      ]
    },
    {
      "metadata": {
        "id": "3cM4rlYkHefJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "it6I1_K7HTub",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.1. Download Dataset for Word Embeddings\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4Op66omXKVHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe which data was used with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "QLjf_pm9NiA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_all = df_friend.append(df_pro).append(df_comic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GXgFpxIgl-_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.2. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "qJrVHGYSmYMg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "t8SlvJrNP1dq",
        "colab_type": "code",
        "outputId": "50cb45b7-8728-44be-ac90-a3d342b97551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"friend length: \"+str(len(df_friend[\"Question\"])))\n",
        "print(\"pro length: \"+str(len(df_pro[\"Question\"])))\n",
        "print(\"comic length: \"+str(len(df_comic[\"Question\"])))\n",
        "\n",
        "print(\"number of same questions between friend and pro: \"+str(sum(df_friend[\"Question\"] == df_pro[\"Question\"])))\n",
        "print(\"number of same questions between friend and comic: \"+str(sum(df_friend[\"Question\"] == df_comic[\"Question\"])))\n",
        "print(\"number of same questions between comic and pro: \"+str(sum(df_comic[\"Question\"] == df_pro[\"Question\"])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "friend length: 657\n",
            "pro length: 657\n",
            "comic length: 657\n",
            "number of same questions between friend and pro: 655\n",
            "number of same questions between friend and comic: 655\n",
            "number of same questions between comic and pro: 654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eO4Wj_BADB4_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "questions_word_embedding = df_all[\"Question\"].unique().tolist()\n",
        "\n",
        "tokenized_questions_word_embedding=[]\n",
        "\n",
        "word_list_word_embedding=[]\n",
        "\n",
        "for i in range(0,len(questions_word_embedding)):\n",
        "\n",
        "    questions_word_embedding[i] = re.sub(r\"[0-9]+\", \"\", questions_word_embedding[i])\n",
        "\n",
        "    questions_word_embedding[i] = questions_word_embedding[i].lower()\n",
        "\n",
        "    for keys,values in contraction_dict.items():\n",
        "        questions_word_embedding[i] = questions_word_embedding[i].replace(keys,values)\n",
        "\n",
        "    questions_word_embedding[i] = re.sub(r\"[^a-z0-9]+\", \" \", questions_word_embedding[i])\n",
        "    \n",
        "\n",
        "    tokenized_questions_word_embedding.append(word_tokenize(questions_word_embedding[i]))\n",
        "    \n",
        "    word_list_word_embedding+=word_tokenize(questions_word_embedding[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmceoo51VMHO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_sequence_word_embedding = word_list_word_embedding\n",
        "word_list_word_embedding = list(set(word_list_word_embedding))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "554O81g1V7UY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_dict_word_embedding = {w: i for i, w in enumerate(word_list_word_embedding)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "neSY3LJ2WJrK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "skip_grams=[]\n",
        "for i in range(1,len(word_sequence_word_embedding)-1):\n",
        "    \n",
        "    target = word_dict_word_embedding[word_sequence_word_embedding[i]]\n",
        "    context = [word_dict_word_embedding[word_sequence_word_embedding[i - 1]], word_dict_word_embedding[word_sequence_word_embedding[i + 1]]]\n",
        "        \n",
        "    for w in context:\n",
        "        skip_grams.append([target, w])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FXus8c4zciXU",
        "colab_type": "code",
        "outputId": "764cddfa-4d6d-41a6-a81f-beb6b9f35d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(skip_grams)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "9LSDWxuBjE7B",
        "colab_type": "code",
        "outputId": "4cbfffb8-7e84-43a0-b700-a8042a647928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(word_dict_word_embedding)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "qhAgWf_AmbZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.3. Build Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "AJ8rU7JbiBVS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "TVPuwWgvNjOU",
        "colab_type": "code",
        "outputId": "11f76330-4b4c-4fe5-f2f8-4694075a7c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "cell_type": "code",
      "source": [
        "def prepare_batch(data, size):\n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
        "\n",
        "    for i in random_index:\n",
        "        random_inputs.append(data[i][0])  # target\n",
        "        random_labels.append([data[i][1]])  # context word\n",
        "\n",
        "    return random_inputs, random_labels\n",
        "\n",
        "\n",
        "learning_rate = 0.05\n",
        "batch_size = 256\n",
        "embedding_size = 100\n",
        "\n",
        "sample_size = 128\n",
        "\n",
        "voc_size = len(word_list_word_embedding)\n",
        "\n",
        "\n",
        "inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
        "# placeholder (output) of function tf.nn.nce_loss()\n",
        "labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "\n",
        "# word2vec Model\n",
        "embeddings = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
        "selected_embed = tf.nn.embedding_lookup(embeddings, inputs)\n",
        "\n",
        "# weight and bias for nce_loss() function\n",
        "nce_weights = tf.Variable(tf.random_uniform([voc_size, embedding_size], -1.0, 1.0))\n",
        "nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
        "\n",
        "cost_op = tf.reduce_mean(\n",
        "            tf.nn.nce_loss(nce_weights, nce_biases, labels, selected_embed, sample_size, voc_size))\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost_op)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LNys5HOdISK-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.4. Train Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "Ae8i7Z2kIef-",
        "colab_type": "code",
        "outputId": "f94063b1-80a8-4b4f-f16a-14363ca5ae8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1191
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt_x=[]\n",
        "plt_y=[]\n",
        "\n",
        "\n",
        "### Training Model\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    no_of_epochs = 1000\n",
        "    display_interval = 20\n",
        "\n",
        "    for epoch in range(no_of_epochs):\n",
        "        batch_inputs, batch_labels = prepare_batch(skip_grams, batch_size)\n",
        "        sess.run(train_op, feed_dict={inputs:batch_inputs, labels:batch_labels})\n",
        "\n",
        "        if epoch % display_interval == 0 :\n",
        "            # calculate the cost/accuracy of the current model\n",
        "            cost = sess.run(cost_op, feed_dict={inputs:batch_inputs, labels:batch_labels})\n",
        "\n",
        "            plt_x.append(epoch)\n",
        "            plt_y.append(cost)\n",
        "                              \n",
        "            print(\"Epoch \" + str(epoch) + \", Cost= \" + \"{:.4f}\".format(cost))\n",
        "            \n",
        "            \n",
        "    trained_embeddings = embeddings.eval()\n",
        "    plt.plot(plt_x,plt_y)\n",
        "    plt.xlabel(\"Number of epochs\")\n",
        "    plt.ylabel(\"Training loss\")    \n",
        "    plt.grid()\n",
        "    \n",
        "    saver.save(sess, 'model_final.cpkt')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Cost= 228.9360\n",
            "Epoch 20, Cost= 34.9513\n",
            "Epoch 40, Cost= 17.3219\n",
            "Epoch 60, Cost= 6.2785\n",
            "Epoch 80, Cost= 4.2180\n",
            "Epoch 100, Cost= 3.7127\n",
            "Epoch 120, Cost= 3.2553\n",
            "Epoch 140, Cost= 3.1276\n",
            "Epoch 160, Cost= 3.3485\n",
            "Epoch 180, Cost= 3.1250\n",
            "Epoch 200, Cost= 3.1848\n",
            "Epoch 220, Cost= 3.5144\n",
            "Epoch 240, Cost= 2.9206\n",
            "Epoch 260, Cost= 3.3387\n",
            "Epoch 280, Cost= 2.7165\n",
            "Epoch 300, Cost= 3.0714\n",
            "Epoch 320, Cost= 3.2111\n",
            "Epoch 340, Cost= 2.9532\n",
            "Epoch 360, Cost= 2.8889\n",
            "Epoch 380, Cost= 2.6595\n",
            "Epoch 400, Cost= 2.4975\n",
            "Epoch 420, Cost= 3.6831\n",
            "Epoch 440, Cost= 3.2584\n",
            "Epoch 460, Cost= 2.7800\n",
            "Epoch 480, Cost= 3.1634\n",
            "Epoch 500, Cost= 2.7952\n",
            "Epoch 520, Cost= 3.6449\n",
            "Epoch 540, Cost= 2.7994\n",
            "Epoch 560, Cost= 2.8043\n",
            "Epoch 580, Cost= 3.4017\n",
            "Epoch 600, Cost= 2.9371\n",
            "Epoch 620, Cost= 3.6232\n",
            "Epoch 640, Cost= 3.0907\n",
            "Epoch 660, Cost= 2.6593\n",
            "Epoch 680, Cost= 2.7192\n",
            "Epoch 700, Cost= 3.3493\n",
            "Epoch 720, Cost= 2.8427\n",
            "Epoch 740, Cost= 2.9139\n",
            "Epoch 760, Cost= 2.9919\n",
            "Epoch 780, Cost= 2.5537\n",
            "Epoch 800, Cost= 2.6457\n",
            "Epoch 820, Cost= 2.7265\n",
            "Epoch 840, Cost= 2.6366\n",
            "Epoch 860, Cost= 3.4607\n",
            "Epoch 880, Cost= 2.7003\n",
            "Epoch 900, Cost= 3.0327\n",
            "Epoch 920, Cost= 2.7222\n",
            "Epoch 940, Cost= 3.1005\n",
            "Epoch 960, Cost= 3.1202\n",
            "Epoch 980, Cost= 2.9044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uMCv3YI1IfUo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.5. Save Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "3OwicNPkIqd1",
        "colab_type": "code",
        "outputId": "f6f3e630-e201-4a27-f400-6f8c77376a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "file1 = drive.CreateFile({'title':'model_final.cpkt.data-00000-of-00001'})\n",
        "file1.SetContentFile('model_final.cpkt.data-00000-of-00001')\n",
        "file1.Upload()\n",
        "print('Uploaded file1 with ID {}'.format(file1.get('id')))\n",
        "\n",
        "file2 = drive.CreateFile({'title':'model_final.cpkt.index'})\n",
        "file2.SetContentFile('model_final.cpkt.index')\n",
        "file2.Upload()\n",
        "print('Uploaded file2 with ID {}'.format(file2.get('id')))\n",
        "\n",
        "file3 = drive.CreateFile({'title':'model_final.cpkt.meta'})\n",
        "file3.SetContentFile('model_final.cpkt.meta')\n",
        "file3.Upload()\n",
        "print('Uploaded file3 with ID {}'.format(file3.get('id')))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file1 with ID 1RakM1ojgXaAqYJ-jOyEpZUJ1cphlAmxH\n",
            "Uploaded file2 with ID 1BjI31Z9MUZVGiz35VbmYMPwP0E74SkEv\n",
            "Uploaded file3 with ID 19ycBmSWBmLDnVcSKH-kyc1TdxnCAKhj0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yn16xrDrIs8B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1.6. Load Word Embeddings Model"
      ]
    },
    {
      "metadata": {
        "id": "aCvYoUJdwPuA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "    \n",
        "downloaded = drive.CreateFile({'id': '11T-jl7F5hbqXCNeM71hDm-pST3WR20Q9'})\n",
        "downloaded.GetContentFile('model_final.cpkt.data-00000-of-00001')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '18yzfHsPjJe2yab2nynufi8BiOevgbFlV'})\n",
        "downloaded.GetContentFile('model_final.cpkt.index')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1yY29nQvVenWJ7JIyEty7KyEqYYqRy1xh'})\n",
        "downloaded.GetContentFile('model_final.cpkt.meta')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-IebpYFsIvgh",
        "colab_type": "code",
        "outputId": "9045cec9-1b53-4721-9102-e7510efe4ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    # Restore (Load) the model\n",
        "    saver.restore(sess, \"./model_final.cpkt\")\n",
        "    \n",
        "    trained_embeddings = embeddings.eval()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./model_final.cpkt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ZmKVnnbxTfU",
        "colab_type": "code",
        "outputId": "ab609e2d-479e-4371-d153-34d28743f600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "trained_embeddings.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(504, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "tlCeWT8eeLnd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.2. Seq2Seq model"
      ]
    },
    {
      "metadata": {
        "id": "fwA-NN3EJ4Ig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.1. Apply/Import Word Embedding Model"
      ]
    },
    {
      "metadata": {
        "id": "UAMJrxx-iOVn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "g7PKX1gIePA2",
        "colab_type": "code",
        "outputId": "1ad3b1c8-2da5-4fc1-abe4-bfb09fc111f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "df_all[\"Answer\"].nunique()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "DpYCL17JKZxl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.2. Build Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "R204UIyDKhZ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "metadata": {
        "id": "r6jk6jTGz0wt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def question_tokens_to_vectors(question_tokens):\n",
        "    vec=[]\n",
        "    for s in question_tokens:   \n",
        "        if(s in word_dict_word_embedding.keys()):\n",
        "            vec.append(trained_embeddings[word_dict_word_embedding[s]])\n",
        "        else:\n",
        "            vec.append([0]*embedding_size)\n",
        "    return vec\n",
        "\n",
        "\n",
        "def answer_to_unique_answers_dict(answers):\n",
        "    unique_answers = list(set(answers))\n",
        "    unique_answers.append(\"__B__\")\n",
        "    unique_answers.append(\"__E__\")\n",
        "    unique_answers.append(\"__U__\")\n",
        "    \n",
        "    unique_answers_dict = {w: i for i, w in enumerate(unique_answers)}\n",
        "    \n",
        "    return unique_answers_dict\n",
        "\n",
        "\n",
        "def answer_to_output_batch_and_target_batch(answers, unique_answers_dict):\n",
        "    output_batch=[]\n",
        "    target_batch=[]\n",
        "    for answer in answers:\n",
        "        if(answer in unique_answers_dict.keys()):            \n",
        "            output_data=[unique_answers_dict[\"__B__\"]]+[unique_answers_dict[answer]]\n",
        "            target = [unique_answers_dict[answer]]+[unique_answers_dict[\"__E__\"]]\n",
        "        else:\n",
        "            output_data=[unique_answers_dict[\"__B__\"]]+[unique_answers_dict[\"__U__\"]]\n",
        "            target = [unique_answers_dict[\"__U__\"]]+[unique_answers_dict[\"__E__\"]]\n",
        "        \n",
        "\n",
        "        output_batch.append(np.eye(len(unique_answers_dict))[output_data])        \n",
        "        target_batch.append(target)\n",
        "        \n",
        "    return output_batch,target_batch\n",
        "\n",
        "\n",
        "def questions_tokens_to_input_batch(questions_tokens, training, max_l=0):\n",
        "       \n",
        "    if(training==True):\n",
        "        for i in range(len(questions_tokens)):\n",
        "            max_l = max(max_l,len(questions_tokens[i]))\n",
        "\n",
        "    max_input_words_amount = max_l\n",
        "\n",
        "    input_batch=[]\n",
        "    for i in range(len(questions_tokens)):\n",
        "        vs = question_tokens_to_vectors(questions_tokens[i])\n",
        "        l = len(vs)\n",
        "        if(l<max_input_words_amount):\n",
        "            for j in range(max_input_words_amount-l):\n",
        "                vs.append([0]*embedding_size)\n",
        "        input_batch.append(vs)\n",
        "    return input_batch\n",
        "\n",
        "\n",
        "def make_batch(questions_tokens, answers, unique_answers_dict,training, max_l=0):\n",
        "    input_batch = questions_tokens_to_input_batch(questions_tokens,training, max_l)\n",
        "    output_batch,target_batch = answer_to_output_batch_and_target_batch(answers,unique_answers_dict)\n",
        "    return input_batch, output_batch, target_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1gbCD-CD6JW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def build_and_model(questions_tokens, answers):\n",
        "    \n",
        "    max_l = 0\n",
        "    for i in range(len(questions_tokens)):\n",
        "        max_l = max(max_l,len(questions_tokens[i]))\n",
        "\n",
        "    ### Setting Hyperparameters\n",
        "    \n",
        "    n_hidden = 128\n",
        "    \n",
        "    unique_answers_dict = answer_to_unique_answers_dict(answers)\n",
        "    n_class = len(unique_answers_dict)\n",
        "\n",
        "\n",
        "    ### Neural Network Model\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    # encoder/decoder shape = [batch size, time steps, input size]\n",
        "    enc_input = tf.placeholder(tf.float32, [None, None, embedding_size])\n",
        "    dec_input = tf.placeholder(tf.float32, [None, None, len(unique_answers_dict)])\n",
        "\n",
        "    # target shape = [batch size, time steps]\n",
        "    targets = tf.placeholder(tf.int64, [None, None])\n",
        "\n",
        "\n",
        "    # Encoder Cell\n",
        "    with tf.variable_scope('encode'):\n",
        "        enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
        "        enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
        "\n",
        "        outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input,\n",
        "                                                dtype=tf.float32)\n",
        "    # Decoder Cell\n",
        "    with tf.variable_scope('decode'):\n",
        "        dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
        "        dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
        "\n",
        "        # [IMPORTANT] Setting enc_states as inital_state of decoder cell\n",
        "        outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, dec_input,\n",
        "                                                initial_state=enc_states,\n",
        "                                                dtype=tf.float32)\n",
        "\n",
        "    model = tf.layers.dense(outputs, n_class, activation=None)\n",
        "        \n",
        "    return enc_input,dec_input,targets, model, unique_answers_dict, max_l\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cJUXr8TthJsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "46775680-0270-4888-d074-3c85c3887a3f"
      },
      "cell_type": "code",
      "source": [
        "enc_input_friend, dec_input_friend, targets_friend, model_friend, unique_answers_dict_friend, max_l_friend = build_and_model(friend_q, friend_a)\n",
        "#enc_input_pro，dec_input_pro，targets_pro, model_pro, unique_answers_dict_pro, max_l_pro = build_and_model(pro_q, pro_a)\n",
        "#enc_input_comic，dec_input_comic，targets_comic, model_comic, unique_answers_dict_comic,max_l_comic = build_and_model(comic_q, comic_a)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-30-349aa62a0dc3>:30: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-30-349aa62a0dc3>:34: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-30-349aa62a0dc3>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6BaOiaGRLW7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.3. Train Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "qv6uDZhNhIJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(enc_input,dec_input,targets, model, q, a, unique_answers_dict, ch, training=True):\n",
        "    \n",
        "    print(\"Train \"+ch)\n",
        "    \n",
        "    learning_rate = 0.002\n",
        "    total_epoch = 200\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=targets))\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "    \n",
        "    input_batch, output_batch, target_batch = make_batch(q, a, unique_answers_dict, training=True)\n",
        "    \n",
        "    ### Training Model\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    for epoch in range(total_epoch):\n",
        "        _, loss = sess.run([optimizer, cost],\n",
        "                           feed_dict={enc_input: input_batch,\n",
        "                                      dec_input: output_batch,\n",
        "                                      targets: target_batch})\n",
        "        if epoch % 10 == 0:\n",
        "            print('Epoch:', '%04d' % (epoch + 1),\n",
        "                  'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "    print('Training completed')\n",
        "    saver.save(sess, ch+'_model.cpkt')\n",
        "    return sess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lVQnUSX1LZ6C",
        "colab_type": "code",
        "outputId": "840a446a-eb11-40d4-a9be-3cdc6f808c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "sess_friend = train_model(enc_input_friend,dec_input_friend,targets_friend, model_friend, friend_q, friend_a, unique_answers_dict_friend, \"friend\", True)\n",
        "#train_model(enc_input_pro，dec_input_pro，targets_pro, model_pro, pro_q, pro_a, unique_answers_dict_pro, \"pro\", True)\n",
        "#train_model(enc_input_comic，dec_input_comic，targets_comic, model_comic, comic_q, comic_a, unique_answers_dict_comic, \"comic\", True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train friend\n",
            "Epoch: 0001 cost = 4.674739\n",
            "Epoch: 0011 cost = 2.389165\n",
            "Epoch: 0021 cost = 2.265370\n",
            "Epoch: 0031 cost = 2.167023\n",
            "Epoch: 0041 cost = 2.040385\n",
            "Epoch: 0051 cost = 1.866873\n",
            "Epoch: 0061 cost = 1.661713\n",
            "Epoch: 0071 cost = 1.410520\n",
            "Epoch: 0081 cost = 1.165230\n",
            "Epoch: 0091 cost = 0.914677\n",
            "Epoch: 0101 cost = 0.726531\n",
            "Epoch: 0111 cost = 0.583719\n",
            "Epoch: 0121 cost = 0.475208\n",
            "Epoch: 0131 cost = 0.401341\n",
            "Epoch: 0141 cost = 0.340026\n",
            "Epoch: 0151 cost = 0.291598\n",
            "Epoch: 0161 cost = 0.276942\n",
            "Epoch: 0171 cost = 0.251604\n",
            "Epoch: 0181 cost = 0.258146\n",
            "Epoch: 0191 cost = 0.241831\n",
            "Training completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-2feNpG-LZx2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.4. Save Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "sflUAgV4L1o8",
        "colab_type": "code",
        "outputId": "e35333cf-f919-4b21-e6a2-ea5b08b93231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "file1 = drive.CreateFile({'title':'friend_model.cpkt.data-00000-of-00001'})\n",
        "file1.SetContentFile('friend_model.cpkt.data-00000-of-00001')\n",
        "file1.Upload()\n",
        "print('Uploaded file1 with ID {}'.format(file1.get('id')))\n",
        "\n",
        "file2 = drive.CreateFile({'title':'friend_model.cpkt.index'})\n",
        "file2.SetContentFile('friend_model.cpkt.index')\n",
        "file2.Upload()\n",
        "print('Uploaded file2 with ID {}'.format(file2.get('id')))\n",
        "\n",
        "file3 = drive.CreateFile({'title':'friend_model.cpkt.meta'})\n",
        "file3.SetContentFile('friend_model.cpkt.meta')\n",
        "file3.Upload()\n",
        "print('Uploaded file3 with ID {}'.format(file3.get('id')))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file1 with ID 1xcFbCtAGxxWULs2rdRyPLD9jEB0mAE5U\n",
            "Uploaded file2 with ID 18XvbG6K6lcoqwhZmgz1OlWDWAwvgh_Cn\n",
            "Uploaded file3 with ID 1wCFJH4vdVDEYJEB7mQbQxLGLrLMn_GvL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4zFo6YppL6w3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2.5. Load Seq2Seq Model"
      ]
    },
    {
      "metadata": {
        "id": "OtNxLzDGMCan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "    \n",
        "downloaded = drive.CreateFile({'id': '1xcFbCtAGxxWULs2rdRyPLD9jEB0mAE5U'})\n",
        "downloaded.GetContentFile('friend_model.cpkt.data-00000-of-00001')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '18XvbG6K6lcoqwhZmgz1OlWDWAwvgh_Cn'})\n",
        "downloaded.GetContentFile('friend_model.cpkt.index')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1wCFJH4vdVDEYJEB7mQbQxLGLrLMn_GvL'})\n",
        "downloaded.GetContentFile('friend_model.cpkt.meta')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9yZJftkrval",
        "colab_type": "code",
        "outputId": "092f29b6-350a-4f35-87d2-d68c9bef42fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "    \n",
        "sess_friend=  tf.Session()\n",
        "saver.restore(sess_friend, \"./friend_model.cpkt\")\n",
        "    \n",
        "    "
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./friend_model.cpkt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a4mpRpocePLN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3 - Evaluation (Running chatbot)"
      ]
    },
    {
      "metadata": {
        "id": "KEW1zMgVMREr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1. Start chatting"
      ]
    },
    {
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab_type": "code",
        "outputId": "dde12c74-2330-456d-fdbd-1bcbd04e483b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "cell_type": "code",
      "source": [
        "def pre_process_user_sentence(question, max_l):\n",
        "      \n",
        "    question = re.sub(r\"[0-9]+\", \"\", question)\n",
        "    question = question.lower()\n",
        "\n",
        "    for keys,values in contraction_dict.items():\n",
        "        question = question.replace(keys,values)\n",
        "\n",
        "    question = re.sub(r\"[^a-z0-9]+\", \" \", question)\n",
        "    question = remove_stopwords(question)\n",
        "\n",
        "    result = word_tokenize(question)\n",
        "            \n",
        "    return result[:max_l]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Answer the question using the trained model\n",
        "def answer(sentence, sess, model, enc_input, dec_input, targets, unique_answers_dict, Training, max_l):\n",
        "    \n",
        "    q = pre_process_user_sentence(sentence, max_l)\n",
        "\n",
        "    print(q)\n",
        "    \n",
        "    input_batch, output_batch, target_batch = make_batch([q],[\"__U__\"],unique_answers_dict, Training, max_l)\n",
        "    \n",
        "    print(input_batch)\n",
        "    \n",
        "    prediction = tf.argmax(model, 2)\n",
        "    \n",
        "    result = sess.run(prediction,\n",
        "                      feed_dict={enc_input: input_batch,\n",
        "                                 dec_input: output_batch,\n",
        "                                 targets: target_batch})\n",
        "        \n",
        "    r= result[0][0]\n",
        "    decoded=\"x\"\n",
        "    \n",
        "    for keys, values in unique_answers_dict.items():    \n",
        "        if values == r:\n",
        "            decoded=keys\n",
        "    \n",
        "    return decoded\n",
        "\n",
        "\n",
        "qq=\"do you want to grab a cup of coffee with me tomorrow\"\n",
        "print(qq , ' ->', answer(qq, sess_friend, model_friend, enc_input_friend, dec_input_friend, targets_friend, unique_answers_dict_friend, False, max_l_friend ))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['want', 'grab', 'cup', 'coffee']\n",
            "[[array([-7.46983111e-01,  8.48606706e-01, -5.14037609e-01,  7.94114023e-02,\n",
            "        1.06099892e+00,  1.04950450e-01, -1.54377997e-01, -7.55737245e-01,\n",
            "        3.32340449e-01, -2.26202324e-01, -1.12365335e-01,  3.79551709e-01,\n",
            "        6.53641045e-01, -8.65609348e-01,  7.30691612e-01, -8.29740167e-01,\n",
            "       -1.04402435e+00, -1.41110981e-03,  4.33476776e-01, -1.10052454e+00,\n",
            "        1.22384155e+00,  4.87098873e-01, -8.56844902e-01,  3.34567070e-01,\n",
            "       -2.08825548e-03, -4.12360162e-01, -1.04785931e+00,  9.55819130e-01,\n",
            "       -3.95761162e-01,  2.92688102e-01,  7.07427561e-01,  2.68609285e-01,\n",
            "        1.63439676e-01, -1.76105797e-01, -9.37981725e-01,  1.57927275e-01,\n",
            "        2.03504339e-01, -7.52285480e-01, -4.63904254e-02,  2.09470367e+00,\n",
            "       -1.52433646e+00,  2.31113076e-01, -4.02097344e-01, -8.88986051e-01,\n",
            "       -5.44437885e-01,  9.37209278e-03,  1.15988009e-01,  1.84021872e-02,\n",
            "        5.33278249e-02, -9.42409873e-01,  1.18416414e-01,  1.37730762e-01,\n",
            "        8.75999212e-01,  3.03598851e-01, -2.54175633e-01, -5.06275415e-01,\n",
            "        2.53824834e-02, -7.60070503e-01, -4.59856570e-01, -9.07316923e-01,\n",
            "       -2.95696706e-01,  2.33715758e-01,  3.37376922e-01,  9.49116290e-01,\n",
            "        6.62274063e-01, -4.41169798e-01, -2.79347628e-01, -3.54963422e-01,\n",
            "        7.10275099e-02,  2.06288636e-01, -7.81418663e-03,  8.84830713e-01,\n",
            "       -3.66800696e-01,  3.66857946e-01,  8.32601339e-02,  1.93205088e-01,\n",
            "        8.45523894e-01, -1.43060014e-01,  1.20983207e+00,  7.53576383e-02,\n",
            "        6.47040248e-01, -1.77133918e+00,  4.65942740e-01, -1.07248656e-01,\n",
            "       -3.04942787e-01, -1.15810740e+00,  2.87852506e-03, -1.54996574e-01,\n",
            "       -9.86660123e-02,  9.53906357e-01, -6.64869010e-01, -8.69130075e-01,\n",
            "       -6.43273234e-01,  6.46821678e-01, -2.11531837e-02, -1.02654546e-01,\n",
            "       -2.89165467e-01, -8.50627720e-01, -3.94895732e-01, -3.04583877e-01],\n",
            "      dtype=float32), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n",
            "do you want to grab a cup of coffee with me tomorrow  -> Cool.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P28Z1k36MZuo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2. Change Personality"
      ]
    },
    {
      "metadata": {
        "id": "U8OBtJfvMgL_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Explain how to change personality (What is the command for changing personality?). *"
      ]
    },
    {
      "metadata": {
        "id": "wTLyQEeZMZ2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y50Ep8KKMZ99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.3. Save chat log"
      ]
    },
    {
      "metadata": {
        "id": "bbZ6oOu6MaGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JISqR3jjMwwU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.4. End chatting"
      ]
    },
    {
      "metadata": {
        "id": "nT_DeoHSMw49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HpomO_3YNI5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.5. Execute program"
      ]
    },
    {
      "metadata": {
        "id": "cDkQJ9i_NH9D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Please make sure your program  is running properly.***\n",
        "\n",
        "***Functions for downloading (from Google Drive) and loading models (both word embeddings and Seq2Seq) need to be called!*** \n"
      ]
    },
    {
      "metadata": {
        "id": "_7J5hS_SOIUU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.5.1. Execute program - training mode"
      ]
    },
    {
      "metadata": {
        "id": "_woLwuU3Mk3w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Please include lines to train the bot.*"
      ]
    },
    {
      "metadata": {
        "id": "xhWYz7NQOfLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "65cZTuQ_OeI7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.5.2. Execute program - chatting mode"
      ]
    },
    {
      "metadata": {
        "id": "D7LrbcP_PKap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Please include lines to start chatting with the bot.*"
      ]
    },
    {
      "metadata": {
        "id": "QVvzZsB7PbYf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Please comment your code\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfv8rWTKPzeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Object Oriented Programming codes here"
      ]
    },
    {
      "metadata": {
        "id": "TS23AjBRSZaX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*If you have multiple classes use multiple code snippets to add them.*"
      ]
    },
    {
      "metadata": {
        "id": "wSJJ4zRFQy1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If you used OOP style, use this sectioon"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}